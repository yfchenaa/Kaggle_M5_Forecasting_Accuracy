{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from  datetime import datetime, timedelta\n",
    "import gc\n",
    "import numpy as np, pandas as pd\n",
    "from derive_functions.derive_date_var import derive_calender_feats\n",
    "from derive_functions.data_prepare_func import create_dt,reduce_mem_usage\n",
    "from derive_functions.derive_lag_mean_feats import create_lag_feats,create_lag_mean_feats\n",
    "from derive_functions.derive_mean_feats_cat import get_df_cat\n",
    "from derive_functions.derive_mean_feats_dept import get_df_dept\n",
    "from derive_functions.derive_mean_feats_id import get_df_id\n",
    "from derive_functions.derive_mean_feats_item import get_df_item\n",
    "from derive_functions.derive_mean_feats_state import get_df_state\n",
    "from derive_functions.derive_mean_feats_store import get_df_store\n",
    "from derive_functions.derive_deviation_feats import get_deviation_feats\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data/processed_data/df_train_var_all_0626_CA_subset.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 训练测试数据切分及预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = data.copy(deep=True).reset_index(drop=True)\n",
    "# data_train = data[data.date<='2016-04-24'].copy(deep=True).reset_index(drop=True)\n",
    "# data_test = data[data.date>'2015-12-20'].copy(deep=True).reset_index(drop=True)\n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2014-09-06 00:00:00')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.date.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-05-22 00:00:00')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_feats=[]\n",
    "for i in data_train.columns:\n",
    "    if 'per_store' in i:\n",
    "        store_feats.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_feats = ['d','date','wm_yr_wk','sales','weekday','revenue','id','state_id']\n",
    "cat_feats = ['item_id', 'dept_id','cat_id','store_id'] + [\"wday\",\"event_name_1\", \"event_name_2\", \"event_type_1\", \"event_type_2\"]\n",
    "train_cols = data_train.columns[~data_train.columns.isin(useless_feats)]\n",
    "X_train = data_train[train_cols]\n",
    "y_train = data_train[\"sales\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 训练验证数据切分及预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 随机切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(111)\n",
    "del data_train\n",
    "gc.collect()\n",
    "fake_valid_inds = np.random.choice(X_train.index.values, 1000000, replace = False)\n",
    "train_inds = np.setdiff1d(X_train.index.values, fake_valid_inds)\n",
    "train_data = lgb.Dataset(X_train.loc[train_inds] , label = y_train.loc[train_inds], \n",
    "                         categorical_feature=cat_feats, free_raw_data=False)\n",
    "fake_valid_data = lgb.Dataset(X_train.loc[fake_valid_inds], label = y_train.loc[fake_valid_inds],\n",
    "                              categorical_feature=cat_feats,\n",
    "                 free_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 2.57617\n",
      "[100]\tvalid_0's rmse: 2.32373\n",
      "[150]\tvalid_0's rmse: 2.25534\n",
      "[200]\tvalid_0's rmse: 2.21923\n",
      "[250]\tvalid_0's rmse: 2.19847\n",
      "[300]\tvalid_0's rmse: 2.18567\n",
      "[350]\tvalid_0's rmse: 2.17704\n",
      "[400]\tvalid_0's rmse: 2.16825\n",
      "[450]\tvalid_0's rmse: 2.16064\n",
      "[500]\tvalid_0's rmse: 2.15388\n",
      "[550]\tvalid_0's rmse: 2.14781\n",
      "[600]\tvalid_0's rmse: 2.14183\n",
      "[650]\tvalid_0's rmse: 2.13618\n",
      "[700]\tvalid_0's rmse: 2.13148\n",
      "[750]\tvalid_0's rmse: 2.12759\n",
      "[800]\tvalid_0's rmse: 2.12351\n",
      "[850]\tvalid_0's rmse: 2.11966\n",
      "[900]\tvalid_0's rmse: 2.11629\n",
      "[950]\tvalid_0's rmse: 2.11305\n",
      "[1000]\tvalid_0's rmse: 2.10986\n",
      "[1050]\tvalid_0's rmse: 2.10737\n",
      "[1100]\tvalid_0's rmse: 2.10489\n",
      "[1150]\tvalid_0's rmse: 2.10239\n",
      "[1200]\tvalid_0's rmse: 2.10022\n",
      "Wall time: 22min 23s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x248832001c8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "## 新加2个feats\n",
    "params = {\n",
    "        \"objective\" : \"tweedie\",\n",
    "        'tweedie_variance_power': 1.1,\n",
    "        \"metric\" :\"rmse\",\n",
    "        \"force_row_wise\" : True,\n",
    "        \"learning_rate\" : 0.025,\n",
    "        \"subsample\":0.5,\n",
    "        \"sub_feature\" : 0.5,\n",
    "        \"bagging_freq\" : 1,\n",
    "        \"lambda_l2\" : 0.1,\n",
    "        \"metric\": [\"rmse\"],\n",
    "    'verbosity': 1,\n",
    "    'num_iterations' : 1200,\n",
    "    'num_leaves': 2**10-1,\n",
    "    \"min_data_in_leaf\": 2**12-1,\n",
    "}\n",
    "#lr:0.03\n",
    "#1400\n",
    "#subsample:0.525\n",
    "m_lgb = lgb.train(params, train_data, valid_sets = [fake_valid_data], verbose_eval=50)\n",
    "m_lgb.save_model('model/random_split/model_tweedie_CA_var_all_new_v2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 最后1个半月的数据作为验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_valid_inds = data_train[data_train.date>'2016-04-07'].index.values\n",
    "del data_train\n",
    "gc.collect()\n",
    "\n",
    "train_inds = np.setdiff1d(X_train.index.values, fake_valid_inds)\n",
    "train_data = lgb.Dataset(X_train.loc[train_inds] , label = y_train.loc[train_inds], \n",
    "                         categorical_feature=cat_feats, free_raw_data=False)\n",
    "fake_valid_data = lgb.Dataset(X_train.loc[fake_valid_inds], label = y_train.loc[fake_valid_inds],\n",
    "                              categorical_feature=cat_feats,\n",
    "                 free_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 2.97471\n",
      "[100]\tvalid_0's rmse: 2.51596\n",
      "[150]\tvalid_0's rmse: 2.27421\n",
      "[200]\tvalid_0's rmse: 2.16312\n",
      "[250]\tvalid_0's rmse: 2.11132\n",
      "[300]\tvalid_0's rmse: 2.08274\n",
      "[350]\tvalid_0's rmse: 2.06243\n",
      "[400]\tvalid_0's rmse: 2.0466\n",
      "[450]\tvalid_0's rmse: 2.0341\n",
      "[500]\tvalid_0's rmse: 2.02388\n",
      "[550]\tvalid_0's rmse: 2.01695\n",
      "[600]\tvalid_0's rmse: 2.01292\n",
      "[650]\tvalid_0's rmse: 2.00956\n",
      "[700]\tvalid_0's rmse: 2.00644\n",
      "[750]\tvalid_0's rmse: 2.00463\n",
      "[800]\tvalid_0's rmse: 2.00328\n",
      "[850]\tvalid_0's rmse: 2.00176\n",
      "[900]\tvalid_0's rmse: 2.00083\n",
      "2020-06-30 21:20:56.552478\n",
      "Wall time: 15min 9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x23758b45e48>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "## 新加2个feats\n",
    "params = {\n",
    "        \"objective\" : \"tweedie\",\n",
    "        'tweedie_variance_power': 1.1,\n",
    "        \"metric\" :\"rmse\",\n",
    "        \"force_row_wise\" : True,\n",
    "        \"learning_rate\" : 0.01,\n",
    "        \"subsample\":0.5,\n",
    "        \"sub_feature\" : 0.6,\n",
    "        \"bagging_freq\" : 1,\n",
    "        \"lambda_l2\" : 0.1,\n",
    "        \"metric\": [\"rmse\"],\n",
    "    'verbosity': 1,\n",
    "    'max_bin':100,\n",
    "    'num_iterations' : 900,\n",
    "    'num_leaves': 2**8-1,\n",
    "    \"min_data_in_leaf\": 2**12-1,\n",
    "}\n",
    "\n",
    "m_lgb = lgb.train(params, train_data, valid_sets = [fake_valid_data], verbose_eval=50)\n",
    "print(datetime.now())\n",
    "m_lgb.save_model('model/time_split/model_tweedie_CA_var_all_v8.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
