{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from  datetime import datetime, timedelta\n",
    "import gc\n",
    "import numpy as np, pandas as pd\n",
    "from derive_functions.derive_date_var import derive_calender_feats\n",
    "from derive_functions.data_prepare_func import create_dt,reduce_mem_usage\n",
    "from derive_functions.derive_lag_mean_feats import create_lag_feats,create_lag_mean_feats\n",
    "from derive_functions.derive_mean_feats_cat import get_df_cat\n",
    "from derive_functions.derive_mean_feats_dept import get_df_dept\n",
    "from derive_functions.derive_mean_feats_id import get_df_id\n",
    "from derive_functions.derive_mean_feats_item import get_df_item\n",
    "from derive_functions.derive_mean_feats_state import get_df_state\n",
    "from derive_functions.derive_mean_feats_store import get_df_store\n",
    "from derive_functions.derive_deviation_feats import get_deviation_feats\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data/processed_data/df_train_var_all_0626_WI_subset.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 训练测试数据切分及预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = data.copy(deep=True).reset_index(drop=True)\n",
    "# data_test = data[data.date>'2015-12-20'].copy(deep=True).reset_index(drop=True)\n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_feats=[]\n",
    "for i in data_train.columns:\n",
    "    if 'per_store' in i:\n",
    "        store_feats.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_feats = ['d','date','wm_yr_wk','sales','weekday','revenue','id','state_id']\n",
    "cat_feats = ['item_id', 'dept_id','cat_id','store_id'] + [\"wday\",\"event_name_1\", \"event_name_2\", \"event_type_1\", \"event_type_2\"]\n",
    "train_cols = data_train.columns[~data_train.columns.isin(useless_feats)]\n",
    "X_train = data_train[train_cols]\n",
    "y_train = data_train[\"sales\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-29 20:25:25.851888\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 训练验证数据切分及训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 随机切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(666)\n",
    "\n",
    "fake_valid_inds = np.random.choice(X_train.index.values, 1000000, replace = False)\n",
    "train_inds = np.setdiff1d(X_train.index.values, fake_valid_inds)\n",
    "train_data = lgb.Dataset(X_train.loc[train_inds] , label = y_train.loc[train_inds], \n",
    "                         categorical_feature=cat_feats,\n",
    "                         free_raw_data=False)\n",
    "fake_valid_data = lgb.Dataset(X_train.loc[fake_valid_inds], label = y_train.loc[fake_valid_inds],\n",
    "                              categorical_feature=cat_feats,\n",
    "                             free_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 2.40657\n",
      "[100]\tvalid_0's rmse: 2.20151\n",
      "[150]\tvalid_0's rmse: 2.15869\n",
      "[200]\tvalid_0's rmse: 2.13479\n",
      "[250]\tvalid_0's rmse: 2.11779\n",
      "[300]\tvalid_0's rmse: 2.10595\n",
      "[350]\tvalid_0's rmse: 2.09719\n",
      "[400]\tvalid_0's rmse: 2.08956\n",
      "[450]\tvalid_0's rmse: 2.08277\n",
      "[500]\tvalid_0's rmse: 2.07671\n",
      "[550]\tvalid_0's rmse: 2.07117\n",
      "[600]\tvalid_0's rmse: 2.06597\n",
      "[650]\tvalid_0's rmse: 2.06133\n",
      "[700]\tvalid_0's rmse: 2.05742\n",
      "[750]\tvalid_0's rmse: 2.05314\n",
      "[800]\tvalid_0's rmse: 2.04973\n",
      "[850]\tvalid_0's rmse: 2.04689\n",
      "[900]\tvalid_0's rmse: 2.04401\n",
      "[950]\tvalid_0's rmse: 2.04085\n",
      "[1000]\tvalid_0's rmse: 2.03823\n",
      "[1050]\tvalid_0's rmse: 2.03526\n",
      "[1100]\tvalid_0's rmse: 2.03293\n",
      "[1150]\tvalid_0's rmse: 2.03049\n",
      "[1200]\tvalid_0's rmse: 2.02843\n",
      "Wall time: 22min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 新增加mode数据两列\n",
    "params = {\n",
    "        \"objective\" : \"tweedie\",\n",
    "        'tweedie_variance_power': 1.1,\n",
    "        \"metric\" :\"rmse\",\n",
    "        \"force_row_wise\" : True,\n",
    "        \"learning_rate\" : 0.025,\n",
    "        \"subsample\":0.5,\n",
    "        \"sub_feature\" : 0.6,\n",
    "        \"bagging_freq\" : 1,\n",
    "        \"lambda_l2\" : 0.1,\n",
    "        \"metric\": [\"rmse\"],\n",
    "    'verbosity': 1,\n",
    "    'num_iterations' : 1200,\n",
    "    'num_leaves': 2**11-1,\n",
    "    \"min_data_in_leaf\": 2**12-1,\n",
    "}\n",
    "\n",
    "m_lgb = lgb.train(params, train_data, valid_sets = [fake_valid_data], verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x24b1166fd08>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_lgb.save_model('model/random_split/model_tweedie_WI_var_all.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 最后一个半月作为验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_valid_inds = data_train[data_train.date>'2016-04-07'].index.values\n",
    "del data_train\n",
    "gc.collect()\n",
    "\n",
    "train_inds = np.setdiff1d(X_train.index.values, fake_valid_inds)\n",
    "train_data = lgb.Dataset(X_train.loc[train_inds] , label = y_train.loc[train_inds], \n",
    "                         categorical_feature=cat_feats, free_raw_data=False)\n",
    "fake_valid_data = lgb.Dataset(X_train.loc[fake_valid_inds], label = y_train.loc[fake_valid_inds],\n",
    "                              categorical_feature=cat_feats,\n",
    "                 free_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 3.30481\n",
      "[100]\tvalid_0's rmse: 2.81684\n",
      "[150]\tvalid_0's rmse: 2.54717\n",
      "[200]\tvalid_0's rmse: 2.4109\n",
      "[250]\tvalid_0's rmse: 2.34162\n",
      "[300]\tvalid_0's rmse: 2.30299\n",
      "[350]\tvalid_0's rmse: 2.27949\n",
      "[400]\tvalid_0's rmse: 2.26391\n",
      "[450]\tvalid_0's rmse: 2.25132\n",
      "[500]\tvalid_0's rmse: 2.24206\n",
      "[550]\tvalid_0's rmse: 2.23417\n",
      "[600]\tvalid_0's rmse: 2.22913\n",
      "[650]\tvalid_0's rmse: 2.22471\n",
      "[700]\tvalid_0's rmse: 2.22126\n",
      "[750]\tvalid_0's rmse: 2.21853\n",
      "[800]\tvalid_0's rmse: 2.21631\n",
      "[850]\tvalid_0's rmse: 2.21452\n",
      "[900]\tvalid_0's rmse: 2.21265\n",
      "[950]\tvalid_0's rmse: 2.21135\n",
      "2020-06-30 21:59:01.231299\n",
      "Wall time: 22min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x1ac2dd4af48>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "## 新加2个feats\n",
    "params = {\n",
    "        \"objective\" : \"tweedie\",\n",
    "        'tweedie_variance_power': 1.1,\n",
    "        \"metric\" :\"rmse\",\n",
    "        \"force_row_wise\" : True,\n",
    "        \"learning_rate\" : 0.01,\n",
    "        \"subsample\":0.5,\n",
    "        \"sub_feature\" : 0.6,\n",
    "        \"bagging_freq\" : 1,\n",
    "        \"lambda_l2\" : 0.1,\n",
    "        \"metric\": [\"rmse\"],\n",
    "    'verbosity': 1,\n",
    "    'max_bin':100,\n",
    "    'num_iterations' : 950,\n",
    "    'num_leaves': 2**8-1,\n",
    "    \"min_data_in_leaf\": 2**12-1,\n",
    "}\n",
    "\n",
    "m_lgb = lgb.train(params, train_data, valid_sets = [fake_valid_data], verbose_eval=50)\n",
    "print(datetime.now())\n",
    "m_lgb.save_model('model/time_split/model_tweedie_WI_var_all_v8.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
